{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c056aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Create dummy data with various issues\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'CustomerID': [101, 102, 103, 104, 101, 106, 107, 108, 109, 110],\n",
    "    'Name': ['John', 'Anna', 'Peter', 'Linda', 'John', 'Sara', np.nan, 'Robert', 'Emily', 'Mike'],\n",
    "    'Age': [25, 32, np.nan, 45, 25, 28, 34, np.nan, 29, 33],\n",
    "    'Salary': ['50000', '62000', '75000', '42000', '50000', '68000', '72000', '61000', 'NaN', '69000'],\n",
    "    'Join_Date': ['2020-01-15', '19-03-2021', '2022/07/01', '12-12-2020', '2020-01-15', \n",
    "                 '2023-02-28', '2021-06-15', '2022-11-09', '2020-05-20', '2023-04-01'],\n",
    "    'Country': ['USA', 'UK', 'usa', 'Canada', 'USA', 'UK', 'France', 'canada', 'Germany', 'UK'],\n",
    "    'Purchase_Category': ['Electronics', 'Clothing', 'Books ', 'electronics', 'clothing', \n",
    "                         'Books', 'ELECTRONICS', 'Books', 'Sports', 'clothing'],\n",
    "    'Weight': [150, 68, 72, 165, 150, 58, 82, 70, 65, 72],\n",
    "    'Height': [5.9, 5.4, 6.1, 5.11, 5.9, 5.2, 5.7, 5.8, 5.5, 5.9],\n",
    "    'Active_Member': [1, 'yes', 0, 'no', 1, 'Yes', 1, 'No', 0, 'YES']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50721b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display initial data\n",
    "print(\"Initial Data:\")\n",
    "print(df.head())\n",
    "print(\"\\nData Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe187fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data:\n",
      "   CustomerID   Name   Age  Salary   Join_Date Country Purchase_Category  \\\n",
      "0         101   John  25.0  $50000  2020-01-15     USA       Electronics   \n",
      "1         102   Anna  32.0  $62000  19-03-2021      UK          Clothing   \n",
      "2         103  Peter   NaN   75000  2022/07/01     usa            Books    \n",
      "3         104  Linda  45.0   42000  12-12-2020  Canada       electronics   \n",
      "4         101   John  25.0   50000  2020-01-15     USA          clothing   \n",
      "\n",
      "   Weight  Height Active_Member  \n",
      "0     150    5.90             1  \n",
      "1      68    5.40           yes  \n",
      "2      72    6.10             0  \n",
      "3     165    5.11            no  \n",
      "4     150    5.90             1  \n",
      "\n",
      "Data Shape: (10, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display initial data\n",
    "print(\"Initial Data:\")\n",
    "print(df.head())\n",
    "print(\"\\nData Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07721745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Removing Duplicates ===\n",
      "Duplicates before: 0\n"
     ]
    }
   ],
   "source": [
    "# 1. Remove Duplicates\n",
    "print(\"\\n=== Removing Duplicates ===\")\n",
    "print(\"Duplicates before:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42b96923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates after: 0\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "print(\"Duplicates after:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ed5efe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Handling Missing Values ===\n",
      "Missing values before:\n",
      "CustomerID           0\n",
      "Name                 1\n",
      "Age                  2\n",
      "Salary               0\n",
      "Join_Date            0\n",
      "Country              0\n",
      "Purchase_Category    0\n",
      "Weight               0\n",
      "Height               0\n",
      "Active_Member        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Handle Missing Values\n",
    "print(\"\\n=== Handling Missing Values ===\")\n",
    "print(\"Missing values before:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b8523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Age with median\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "# Fill Name with 'Unknown'\n",
    "df['Name'] = df['Name'].fillna('Unknown')\n",
    "\n",
    "print(\"\\nMissing values after:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898d0a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Correct Data Types\n",
    "print(\"\\n=== Correcting Data Types ===\")\n",
    "# Clean and convert Salary to numeric\n",
    "df['Salary'] = df['Salary'].str.replace('[$,]', '', regex=True).replace('NaN', np.nan)\n",
    "df['Salary'] = pd.to_numeric(df['Salary'])\n",
    "\n",
    "# Convert Join_Date to datetime\n",
    "df['Join_Date'] = pd.to_datetime(df['Join_Date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db268028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Active_Member to binary\n",
    "df['Active_Member'] = df['Active_Member'].replace({'yes': 1, 'Yes': 1, 'YES': 1, 'no': 0, 'No': 0})\n",
    "df['Active_Member'] = df['Active_Member'].astype(int)\n",
    "\n",
    "print(\"\\nData types after correction:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2b74e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Standardize Formats\n",
    "print(\"\\n=== Standardizing Formats ===\")\n",
    "# Standardize country names\n",
    "df['Country'] = df['Country'].str.lower()\n",
    "\n",
    "# Standardize purchase categories\n",
    "df['Purchase_Category'] = df['Purchase_Category'].str.strip().str.lower()\n",
    "\n",
    "# 5. Remove Unwanted Characters\n",
    "df['Purchase_Category'] = df['Purchase_Category'].str.replace('[^a-zA-Z]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "307382ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Handling Outliers ===\n",
      "Outliers detected: 0\n"
     ]
    }
   ],
   "source": [
    "# 6. Fix Structural Errors\n",
    "# Ensure Height is in feet with decimal format\n",
    "df['Height'] = df['Height'].apply(lambda x: round(float(x), 2) if isinstance(x, str) else x)\n",
    "\n",
    "# 7. Handle Outliers\n",
    "print(\"\\n=== Handling Outliers ===\")\n",
    "# Identify outliers using Z-score\n",
    "z_scores = np.abs((df['Weight'] - df['Weight'].mean()) / df['Weight'].std())\n",
    "outliers = df[z_scores > 3]\n",
    "print(\"Outliers detected:\", len(outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920d6564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap outliers at 3 standard deviations\n",
    "df['Weight'] = np.where(z_scores > 3, df['Weight'].mean() + 3*df['Weight'].std(), df['Weight'])\n",
    "\n",
    "# Visualize outliers\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(data=df, y='Weight')\n",
    "plt.title('Weight Before Outlier Handling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e1d2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(data=df, y='Weight')\n",
    "plt.title('Weight After Outlier Handling')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 8. Normalize and Scale Data\n",
    "scaler = MinMaxScaler()\n",
    "df['Height_scaled'] = scaler.fit_transform(df[['Height']])\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "df['Age_standardized'] = standard_scaler.fit_transform(df[['Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39338420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Correct Inconsistent Data\n",
    "df['Country'] = df['Country'].replace({'canada': 'canada', 'usa': 'us', 'uk': 'uk'})\n",
    "\n",
    "# 10. Remove Redundant Features\n",
    "df = df.drop(columns=['Height_scaled', 'Age_standardized']  # Example removal\n",
    "\n",
    "# 11. Fix Column Names\n",
    "df.columns = df.columns.str.lower().str.replace('_', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381361fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Validate Data Integrity\n",
    "assert df['customerid'].is_unique, \"CustomerID should be unique\"\n",
    "assert df['join date'].notnull().all(), \"Join date should not have null values\"\n",
    "\n",
    "# 13. Handle Date and Time Data\n",
    "df['join year'] = df['join date'].dt.year\n",
    "df['join month'] = df['join date'].dt.month_name()\n",
    "\n",
    "# 14. Standardize Units of Measure\n",
    "# Convert weight from pounds to kilograms\n",
    "df['weight'] = df['weight'] * 0.453592"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d217e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Filter Irrelevant Data\n",
    "df = df[df['join year'] >= 2020]\n",
    "\n",
    "# Final cleaned data\n",
    "print(\"\\n=== Final Cleaned Data ===\")\n",
    "print(df.head())\n",
    "print(\"\\nData Shape after cleaning:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeebdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional visualizations\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df.select_dtypes(include=np.number).corr(), annot=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x='purchase category')\n",
    "plt.title('Purchase Category Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40ebcfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Descriptive Statistics ===\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert [['$50000' '$62000' '75000' '42000' '50000' '68000' '72000' '61000' 'NaN'\n  '69000']] to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Numerical statistics\u001b[39;00m\n\u001b[0;32m      9\u001b[0m num_stats \u001b[38;5;241m=\u001b[39m df[numerical_cols]\u001b[38;5;241m.\u001b[39mdescribe()\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[1;32m---> 10\u001b[0m num_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[numerical_cols]\u001b[38;5;241m.\u001b[39mmedian()\n\u001b[0;32m     11\u001b[0m num_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrange\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m num_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m num_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNumerical Statistics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11706\u001b[0m, in \u001b[0;36mDataFrame.median\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11698\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m  11699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmedian\u001b[39m(\n\u001b[0;32m  11700\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11704\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11705\u001b[0m ):\n\u001b[1;32m> 11706\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mmedian(axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m  11707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series):\n\u001b[0;32m  11708\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12431\u001b[0m, in \u001b[0;36mNDFrame.median\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmedian\u001b[39m(\n\u001b[0;32m  12425\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  12426\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12429\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  12430\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 12431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  12432\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmedian, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  12433\u001b[0m     )\n",
      "File \u001b[1;32mc:\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12373\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[0;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  12378\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  12379\u001b[0m )\n",
      "File \u001b[1;32mc:\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11562\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m  11558\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m  11560\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[0;32m  11561\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[1;32m> 11562\u001b[0m res \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreduce(blk_func)\n\u001b[0;32m  11563\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(res, axes\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m  11564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboolean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1500\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1498\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m-> 1500\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mreduce(func)\n\u001b[0;32m   1501\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[0;32m   1503\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[1;32mc:\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:404\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 404\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    407\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32mc:\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11481\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[1;34m(values, axis)\u001b[0m\n\u001b[0;32m  11479\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([result])\n\u001b[0;32m  11480\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m> 11481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:787\u001b[0m, in \u001b[0;36mnanmedian\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    785\u001b[0m     inferred \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values)\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inferred \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 787\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    789\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot convert [['$50000' '$62000' '75000' '42000' '50000' '68000' '72000' '61000' 'NaN'\n  '69000']] to numeric"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Descriptive Statistics\n",
    "# =====================\n",
    "print(\"\\n=== Descriptive Statistics ===\")\n",
    "numerical_cols = ['Age', 'Salary', 'Weight', 'Height']\n",
    "categorical_cols = ['Country', 'Purchase_Category', 'Active_Member']\n",
    "\n",
    "# Numerical statistics\n",
    "num_stats = df[numerical_cols].describe().transpose()\n",
    "num_stats['median'] = df[numerical_cols].median()\n",
    "num_stats['range'] = num_stats['max'] - num_stats['min']\n",
    "print(\"\\nNumerical Statistics:\")\n",
    "print(num_stats[['count', 'mean', 'median', 'std', 'min', 'max', 'range']])\n",
    "\n",
    "# Categorical counts\n",
    "print(\"\\nCategorical Value Counts:\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col.title()} distribution:\")\n",
    "    print(df[col].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2d864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================\n",
    "# Data Visualization\n",
    "# =================\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Histograms for numerical columns\n",
    "for i, col in enumerate(numerical_cols, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.histplot(df[col], kde=True, bins=15, color='skyblue')\n",
    "    plt.title(f'Distribution of {col.title()}', fontsize=12)\n",
    "    plt.xlabel(col.title())\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72b237fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numerical_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Box plots for numerical columns\u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m18\u001b[39m, \u001b[38;5;241m12\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(numerical_cols, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      4\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, i)\n\u001b[0;32m      5\u001b[0m     sns\u001b[38;5;241m.\u001b[39mboxplot(y\u001b[38;5;241m=\u001b[39mdf[col], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlightgreen\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'numerical_cols' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Box plots for numerical columns\n",
    "plt.figure(figsize=(18, 12))\n",
    "for i, col in enumerate(numerical_cols, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.boxplot(y=df[col], color='lightgreen')\n",
    "    plt.title(f'Box Plot of {col.title()}', fontsize=12)\n",
    "    plt.ylabel(col.title())\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec4beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar charts for categorical columns\n",
    "plt.figure(figsize=(18, 12))\n",
    "for i, col in enumerate(categorical_cols, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    ax = sns.countplot(x=df[col], palette='viridis')\n",
    "    plt.title(f'{col.title()} Distribution', fontsize=12)\n",
    "    plt.xlabel(col.title())\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Add percentage labels\n",
    "    total = len(df[col])\n",
    "    for p in ax.patches:\n",
    "        percentage = f'{100 * p.get_height()/total:.1f}%'\n",
    "        x = p.get_x() + p.get_width() / 2\n",
    "        y = p.get_height()\n",
    "        ax.annotate(percentage, (x, y), ha='center', va='bottom')\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional visualization for join year\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='join year', data=df, palette='rocket')\n",
    "plt.title('Customer Join Year Distribution')\n",
    "plt.xlabel('Join Year')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
